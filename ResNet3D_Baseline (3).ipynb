{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "R1P4JYH5cVN0"
      },
      "outputs": [],
      "source": [
        "# Requiremments installation\n",
        "\n",
        "!pip install --quiet torch torchvision torchaudio timm==0.9.16 einops accelerate scikit-learn\n",
        "!pip install --quiet 'git+https://github.com/facebookresearch/pytorchvideo.git'\n",
        "\n",
        "import torch, os, math, random, time, json\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W8B0FZEchaU"
      },
      "outputs": [],
      "source": [
        "# Model Configuration\n",
        "# Replace dataset_root with a path toward split dataset\n",
        "\n",
        "cfg = {\n",
        "    \"dataset_root\": \"/content/drive/MyDrive\",\n",
        "    \"clip_duration\": 13,\n",
        "    \"frames_per_clip\": 8,\n",
        "    \"batch_size\": 20,\n",
        "    \"num_workers\": 0,\n",
        "    \"epochs\": 10,\n",
        "    \"base_lr\":  5e-5,\n",
        "    \"weight_decay\": 5e-3,\n",
        "    \"num_classes\": 5,\n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, random\n",
        "import torch, numpy as np\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import UniformTemporalSubsample\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "from pytorchvideo.transforms import UniformTemporalSubsample\n",
        "from torchvision.transforms import Resize\n",
        "import torch\n",
        "\n",
        "# Video transformation\n",
        "def make_video_transform():\n",
        "    resize = Resize((400, 400))\n",
        "    mean   = torch.tensor([0.45,0.45,0.45]).view(3,1,1,1)\n",
        "    std    = torch.tensor([0.225,0.225,0.225]).view(3,1,1,1)\n",
        "\n",
        "    def video_transform(x: torch.Tensor):\n",
        "\n",
        "        if x.ndim==4 and x.shape[-1]==3:\n",
        "            x = x.permute(3,0,1,2)\n",
        "        elif x.ndim==4 and x.shape[1]==3 and x.shape[0]!=3:\n",
        "            x = x.permute(1,0,2,3)\n",
        "\n",
        "        x = UniformTemporalSubsample(cfg[\"frames_per_clip\"])(x)\n",
        "\n",
        "        C,T,H,W = x.shape\n",
        "        x = x.contiguous().to(torch.float32) / 255.0\n",
        "        x = torch.nn.functional.interpolate(\n",
        "            x.view(C*T,1,H,W),\n",
        "            size=(400,400),\n",
        "            mode=\"bilinear\",\n",
        "            align_corners=False\n",
        "        ).view(C,T,400,400)\n",
        "\n",
        "        return (x - mean.to(x.device)) / std.to(x.device)\n",
        "\n",
        "    return video_transform\n",
        "\n",
        "video_transform = make_video_transform()\n",
        "\n",
        "# Collects 1 clip per video for test and validation set\n",
        "class FirstClipDataset(Dataset):\n",
        "    def __init__(self, labeled_videos, clip_duration, transform):\n",
        "        self.data = labeled_videos\n",
        "        self.clip_duration = clip_duration\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, meta = self.data[idx]\n",
        "        label = meta[\"label\"]\n",
        "        ev = EncodedVideo.from_path(path)\n",
        "        clip = ev.get_clip(0.0, self.clip_duration)\n",
        "        frames = clip[\"video\"]\n",
        "        frames = self.transform(frames)\n",
        "        return {\n",
        "            \"video\":      frames,\n",
        "            \"label\":      torch.tensor(label, dtype=torch.long),\n",
        "            \"video_name\": Path(path).name\n",
        "        }\n",
        "\n",
        "# Returns final dataloader\n",
        "def make_loader(split):\n",
        "    split_dir = os.path.join(cfg[\"dataset_root\"], split)\n",
        "    class_names = sorted(d for d in os.listdir(split_dir)\n",
        "                         if os.path.isdir(os.path.join(split_dir, d)))\n",
        "    class_to_idx = {c:i for i,c in enumerate(class_names)}\n",
        "\n",
        "    pool = []\n",
        "    for cls in class_names:\n",
        "        cls_dir = os.path.join(split_dir, cls)\n",
        "        for ext in (\".mp4\",\".avi\",\".mov\"):\n",
        "            for fp in glob.glob(os.path.join(cls_dir,f\"*{ext}\")):\n",
        "                pool.append((fp, {\"label\": class_to_idx[cls]}))\n",
        "\n",
        "    if split==\"train\":\n",
        "        lbls = [m[\"label\"] for _,m in pool]\n",
        "        counts = np.bincount(lbls, minlength=len(class_names))\n",
        "        w_cls  = 1.0/(counts+1e-6)\n",
        "        w_samp = np.array([w_cls[l] for l in lbls])\n",
        "        p_samp = w_samp / w_samp.sum()\n",
        "        N = len(pool)*2\n",
        "        idxs = np.random.choice(len(pool), size=N, p=p_samp)\n",
        "        videos = [pool[i] for i in idxs]\n",
        "        random.shuffle(videos)\n",
        "    else:\n",
        "        videos = pool\n",
        "\n",
        "    ds = FirstClipDataset(\n",
        "        labeled_videos = videos,\n",
        "        clip_duration  = cfg[\"clip_duration\"],\n",
        "        transform      = video_transform\n",
        "    )\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size  = cfg[\"batch_size\"],\n",
        "        shuffle     = (split==\"train\"),\n",
        "        num_workers = cfg[\"num_workers\"],\n",
        "        pin_memory  = True,\n",
        "    )\n",
        "\n",
        "train_loader = make_loader(\"train\")\n",
        "val_loader   = make_loader(\"val\")\n",
        "test_loader  = make_loader(\"test\")"
      ],
      "metadata": {
        "id": "G9s7iKO7ooGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHnegRi6eKFu"
      },
      "outputs": [],
      "source": [
        "# Build ResNet model\n",
        "\n",
        "import timm, torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "model = models.video.r3d_18(pretrained=True)\n",
        "model = model.to(device)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 5)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHVfzvpAeMP9"
      },
      "outputs": [],
      "source": [
        "# Build accelerator, optimizer, scheduler, helpers\n",
        "\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from accelerate import Accelerator\n",
        "import torch, collections, os, glob\n",
        "\n",
        "acc = Accelerator(mixed_precision=\"fp16\")\n",
        "\n",
        "# Build finite weight vector\n",
        "eps      = 1e-6\n",
        "counts   = torch.tensor(class_counts, dtype=torch.float32)\n",
        "weights  = 1.0 / (counts + eps)\n",
        "weights  = weights / weights.sum()\n",
        "\n",
        "# Focal loss method\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, gamma=2.0, reduction='mean'):\n",
        "        super().__init__()\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "    def forward(self, logits, targets):\n",
        "        ce  = torch.nn.functional.cross_entropy(logits, targets, reduction='none')\n",
        "        pt  = torch.exp(-ce)\n",
        "        fl  = (1 - pt) ** self.gamma * ce\n",
        "        return fl.mean() if self.reduction == 'mean' else fl.sum()\n",
        "\n",
        "criterion = FocalLoss(gamma=2.0).to(device)\n",
        "\n",
        "# Build optimizer, scheduler\n",
        "optimizer  = AdamW(model.parameters(), lr=cfg[\"base_lr\"],\n",
        "                   weight_decay=cfg[\"weight_decay\"])\n",
        "scheduler  = torch.optim.lr_scheduler.StepLR(\n",
        "                 optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "model, optimizer, scheduler = acc.prepare(model, optimizer, scheduler)\n",
        "scaler = GradScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftjwV1Py_jE-"
      },
      "outputs": [],
      "source": [
        "# Class accuracy computation for main training loop\n",
        "\n",
        "def compute_per_class_acc(y_true, y_pred, n_classes):\n",
        "    correct_per_class = np.zeros(n_classes, dtype=np.int32)\n",
        "    total_per_class   = np.zeros(n_classes, dtype=np.int32)\n",
        "    for true, pred in zip(y_true, y_pred):\n",
        "        total_per_class[true] += 1\n",
        "        if true == pred:\n",
        "            correct_per_class[true] += 1\n",
        "    return [(correct_per_class[i] / total_per_class[i] if total_per_class[i] > 0 else 0.0)\n",
        "                     for i in range(n_classes)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eMYYrqneOgb"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def run_epoch(loader, *, train=True, debug=False):\n",
        "\n",
        "    model.train(train) if train else model.eval()\n",
        "\n",
        "    epoch_loss, correct_tot, seen_tot = 0.0, 0, 0\n",
        "    per_class_correct = np.zeros(cfg[\"num_classes\"], dtype=np.int64)\n",
        "    per_class_seen    = np.zeros(cfg[\"num_classes\"], dtype=np.int64)\n",
        "    all_true, all_pred = [], []\n",
        "\n",
        "    try:\n",
        "        total_batches = len(loader)\n",
        "    except TypeError:\n",
        "        total_batches = ceil(len(loader.dataset._labeled_videos) / loader.batch_size)\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Train\" if train else \"Val\",\n",
        "                total=total_batches, leave=False)\n",
        "\n",
        "    for batch in loop:\n",
        "        vids   = batch[\"video\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.no_grad() if not train else torch.enable_grad():\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=use_amp):\n",
        "                logits = model(vids)\n",
        "                loss   = criterion(logits, labels)\n",
        "\n",
        "        if train:\n",
        "            acc.backward(loss)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "        # Performance metrics computation\n",
        "        preds = logits.argmax(1)\n",
        "        bs    = labels.size(0)\n",
        "\n",
        "        epoch_loss += loss.item() * bs\n",
        "        correct_tot += (preds == labels).sum().item()\n",
        "        seen_tot    += bs\n",
        "\n",
        "        for c in range(cfg[\"num_classes\"]):\n",
        "            mask = (labels == c)\n",
        "            per_class_seen[c]    += mask.sum().item()\n",
        "            per_class_correct[c] += (preds[mask] == c).sum().item()\n",
        "\n",
        "        all_true.extend(labels.cpu().tolist())\n",
        "        all_pred.extend(preds.cpu().tolist())\n",
        "\n",
        "        overall_acc = correct_tot / seen_tot\n",
        "        class_accs  = [ (per_class_correct[i] / per_class_seen[i] if per_class_seen[i] else 0)\n",
        "                        for i in range(cfg[\"num_classes\"]) ]\n",
        "        postfix = {\"loss\": f\"{loss.item():.4f}\",\n",
        "                   \"all\":  f\"{overall_acc:.3f}\"}\n",
        "        for i, a in enumerate(class_accs):\n",
        "            postfix[f\"C{i}\"] = f\"{a:.3f}\"\n",
        "        loop.set_postfix(postfix)\n",
        "\n",
        "    # Epoch aggregates\n",
        "    epoch_loss /= seen_tot\n",
        "    overall_acc = correct_tot / seen_tot\n",
        "    class_accs  = [ per_class_correct[i]/per_class_seen[i] if per_class_seen[i] else 0\n",
        "                    for i in range(cfg[\"num_classes\"]) ]\n",
        "\n",
        "    return epoch_loss, overall_acc, class_accs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw8bi14xeQ_F",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Main training loop\n",
        "\n",
        "use_amp=True\n",
        "for epoch in range(cfg[\"epochs\"]):\n",
        "    tr_loss, tr_acc, tr_class_acc = run_epoch(train_loader, train=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        vl_loss, vl_acc, vl_class_acc = run_epoch(val_loader, train=False)\n",
        "        print(\"model.training =\", model.training)\n",
        "\n",
        "    # Optional metrics output\n",
        "    print(f\"Epoch {epoch+1}/{cfg['epochs']}\")\n",
        "    print(\"  Train loss {:.4f}  overall acc {:.3f}\".format(tr_loss, tr_acc))\n",
        "    print(\"  Val   loss {:.4f}  overall acc {:.3f}\".format(vl_loss, vl_acc))\n",
        "    print(\"  Per‑class train acc:\", [\"{:.3f}\".format(a) for a in tr_class_acc])\n",
        "    print(\"  Per‑class val acc:\", \" \".join([f\"C{i}={a:.3f}\" for i, a in enumerate(vl_class_acc)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2S8EZg8eWEi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Test set performance evaluation\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "with torch.no_grad(), torch.amp.autocast(\"cuda\", enabled=use_cuda):\n",
        "    for batch in test_loader:\n",
        "        vids   = batch[\"video\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        logits = model(vids)\n",
        "        all_preds.append(logits.argmax(1).cpu())\n",
        "        all_labels.append(labels.cpu())\n",
        "\n",
        "y_pred  = torch.cat(all_preds).numpy()\n",
        "y_true  = torch.cat(all_labels).numpy()\n",
        "\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "    y_true, y_pred, labels=np.arange(5), zero_division=0\n",
        ")\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=np.arange(5))\n",
        "N  = cm.sum()\n",
        "tp = np.diag(cm)\n",
        "fp = cm.sum(axis=0) - tp\n",
        "fn = cm.sum(axis=1) - tp\n",
        "tn = N - tp - fp - fn\n",
        "acc = (tp + tn) / N\n",
        "\n",
        "class_names = [\"Removal\", \"No Attack\", \"Visual Modification\", \"Text Modification\", \"Addition\"]\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"Attack Class\": class_names,\n",
        "    \"Accuracy\":  acc,\n",
        "    \"Precision\": prec,\n",
        "    \"F1 Score\":  f1,\n",
        "})\n",
        "\n",
        "pd.set_option(\"display.precision\", 5)\n",
        "print(\"\\nPer‑class metrics (for Table 2):\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "print(\"\\nDetailed classification report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names, digits=5))\n",
        "\n",
        "print(\"\\nConfusion matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional model download\n",
        "\n",
        "OUT_PATH = \"\" # Drive path\n",
        "\n",
        "torch.save(model.state_dict(), OUT_PATH)\n",
        "\n",
        "# Optional local download\n",
        "from google.colab import files\n",
        "files.download(OUT_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7I0o3j1kF9k8",
        "outputId": "7457ff2c-e299-4e7d-c291-6d167849cb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_072845d2-60b5-4041-95e7-8cab64c6bd34\", \"resnet3d.pt\", 132755772)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}